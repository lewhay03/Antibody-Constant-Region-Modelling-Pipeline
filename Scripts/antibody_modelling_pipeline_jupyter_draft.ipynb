{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd7b01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\skati\\MSc Bioinformatics BBK\\Antibody-Constant-Region-Modelling-Pipeline\\Scripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Print current working directory\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dde4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the project root using absolute path and adding \"..\" to \n",
    "# move up 1 level from .../Modelling-Pipeline/Scripts -> .../Modelling-Pipeline\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# List of required directories\n",
    "required_dirs = [\n",
    "    \"VCAb_data\",\n",
    "    \"fasta_sequences\",\n",
    "    \"alignments\",\n",
    "    \"pir_files\",\n",
    "    \"atom_files\",\n",
    "    \"models\",\n",
    "    \"pickles\"\n",
    "]\n",
    "\n",
    "# Create each directory if it doesn't exist\n",
    "for dir_name in required_dirs:\n",
    "    os.makedirs(os.path.join(project_root, dir_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380d9276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, columns: (3767, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>H_seq</th>\n",
       "      <th>L_seq</th>\n",
       "      <th>H_coordinate_seq</th>\n",
       "      <th>L_coordinate_seq</th>\n",
       "      <th>H_PDB_numbering</th>\n",
       "      <th>L_PDB_numbering</th>\n",
       "      <th>pdb_H_VC_Boundary</th>\n",
       "      <th>...</th>\n",
       "      <th>resolution</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>HC_species</th>\n",
       "      <th>H_isotype_clean</th>\n",
       "      <th>L_isotype_clean</th>\n",
       "      <th>HC_coordinate_seq</th>\n",
       "      <th>LC_coordinate_seq</th>\n",
       "      <th>HV_seq</th>\n",
       "      <th>LV_seq</th>\n",
       "      <th>disulfide_bond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1a4j</td>\n",
       "      <td>B;H</td>\n",
       "      <td>A;L</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>CYS146(B)-CYS202(B):6.60, CYS139(A)-CYS199(A):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1a4k</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>CYS140(B)-CYS196(B):6.71, CYS134(A)-CYS194(A):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1a4k</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...</td>\n",
       "      <td>ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...</td>\n",
       "      <td>CYS140(H)-CYS196(H):6.65, CYS134(L)-CYS194(L):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1ad0</td>\n",
       "      <td>B;D</td>\n",
       "      <td>A;C</td>\n",
       "      <td>EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...</td>\n",
       "      <td>QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...</td>\n",
       "      <td>EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...</td>\n",
       "      <td>QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG4</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPCSRSTSESTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...</td>\n",
       "      <td>QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...</td>\n",
       "      <td>CYS127(B)-CYS213(A):4.41, CYS140(B)-CYS195(B):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1ad9</td>\n",
       "      <td>B;H</td>\n",
       "      <td>A;L</td>\n",
       "      <td>EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...</td>\n",
       "      <td>EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>114</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG4</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPCSRSTSESTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...</td>\n",
       "      <td>DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...</td>\n",
       "      <td>CYS127(B)-CYS213(A):5.15, CYS140(B)-CYS196(B):...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pdb Hchain Lchain                                              H_seq  \\\n",
       "5   1a4j    B;H    A;L  QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "6   1a4k      B      A  QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "7   1a4k      H      L  QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "11  1ad0    B;D    A;C  EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...   \n",
       "12  1ad9    B;H    A;L  EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...   \n",
       "\n",
       "                                                L_seq  \\\n",
       "5   ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...   \n",
       "6   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "7   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "11  QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...   \n",
       "12  DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...   \n",
       "\n",
       "                                     H_coordinate_seq  \\\n",
       "5   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "6   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "7   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "11  EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...   \n",
       "12  EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...   \n",
       "\n",
       "                                     L_coordinate_seq  \\\n",
       "5   ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...   \n",
       "6   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "7   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "11  QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...   \n",
       "12  DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...   \n",
       "\n",
       "                                      H_PDB_numbering  \\\n",
       "5   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "6   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "7   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "11  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "12  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "\n",
       "                                      L_PDB_numbering pdb_H_VC_Boundary  ...  \\\n",
       "5   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...               120  ...   \n",
       "6   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...               114  ...   \n",
       "7   1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...               114  ...   \n",
       "11  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...               114  ...   \n",
       "12  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...               114  ...   \n",
       "\n",
       "   resolution carbohydrate    HC_species H_isotype_clean  L_isotype_clean  \\\n",
       "5         2.1          NaN  homo_sapiens            IgG1            kappa   \n",
       "6         2.4          NaN  homo_sapiens            IgG1            kappa   \n",
       "7         2.4          NaN  homo_sapiens            IgG1            kappa   \n",
       "11        2.5          NaN  homo_sapiens            IgG4            kappa   \n",
       "12        2.8          NaN  homo_sapiens            IgG4            kappa   \n",
       "\n",
       "                                    HC_coordinate_seq  \\\n",
       "5   ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "6   ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "7   ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "11  ASTKGPSVFPLAPCSRSTSESTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "12  ASTKGPSVFPLAPCSRSTSESTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "\n",
       "                                    LC_coordinate_seq  \\\n",
       "5   RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "6   RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "7   RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "11  RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "12  RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "\n",
       "                                               HV_seq  \\\n",
       "5   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "6   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "7   QVQLLESGPELKKPGETVKISCKASGYTFTNYGMNWVKQAPGKGLK...   \n",
       "11  EVQLLESGGGLVQPGGSLRLSCATSGFTFTDYYMNWVRQAPGKGLE...   \n",
       "12  EIQLVQSGAEVKKPGSSVKVSCKASGYTFTDYYINWMRQAPGQGLE...   \n",
       "\n",
       "                                               LV_seq  \\\n",
       "5   ELVMTQTPLSLPVSLGDQASISCRSSQSLVHSNGNTYLHWYLQKPG...   \n",
       "6   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "7   ELVMTQTPLSLPVSLGDQASISCRSSQSLLHSNGNTYLHWYLQKPG...   \n",
       "11  QTVLTQSPSSLSVSVGDRVTITCRASSSVTYIHWYQQKPGLAPKSL...   \n",
       "12  DIQMTQSPSTLSASVGDRVTITCRSSKSLLHSNGDTFLYWFQQKPG...   \n",
       "\n",
       "                                       disulfide_bond  \n",
       "5   CYS146(B)-CYS202(B):6.60, CYS139(A)-CYS199(A):...  \n",
       "6   CYS140(B)-CYS196(B):6.71, CYS134(A)-CYS194(A):...  \n",
       "7   CYS140(H)-CYS196(H):6.65, CYS134(L)-CYS194(L):...  \n",
       "11  CYS127(B)-CYS213(A):4.41, CYS140(B)-CYS195(B):...  \n",
       "12  CYS127(B)-CYS213(A):5.15, CYS140(B)-CYS196(B):...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import my_run_info\n",
    "#from my_run_info import models_out_dir\n",
    "\n",
    "\n",
    "# Pandas to read csv file as a dataframe\n",
    "df = pd.read_csv(my_run_info.VCAb_dir)\n",
    "\n",
    "# Simplify the naming conventions in certain columns using str.extract(r\"regex_expression\")\n",
    "# This captures the matched word at the start of string, stopping at the first non-word character \"(\"\n",
    "df[\"H_isotype_clean\"] = df[\"Htype\"].str.extract(r\"^(\\w+)\")\n",
    "df[\"L_isotype_clean\"] = df[\"Ltype\"].str.extract(r\"^(\\w+)\")\n",
    "\n",
    "# Reduce dataframe size down to just the key columns (especially the \"_clean\" ones)\n",
    "columns_to_keep = [\n",
    "    \"pdb\",\"Hchain\", \"Lchain\", \"H_seq\", \"L_seq\", \"H_coordinate_seq\", \"L_coordinate_seq\", \n",
    "    \"H_PDB_numbering\", \"L_PDB_numbering\", \"pdb_H_VC_Boundary\", \"pdb_L_VC_Boundary\", \"title\", \"release_date\",\"method\", \"resolution\", \n",
    "    \"carbohydrate\", \"HC_species\", \"H_isotype_clean\", \"L_isotype_clean\", \"HC_coordinate_seq\", \n",
    "    \"LC_coordinate_seq\", \"HV_seq\", \"LV_seq\",\"disulfide_bond\"\n",
    "]\n",
    "df_keep = df[columns_to_keep]\n",
    "\n",
    "# Filter down to rows of interest with conditions. Using wrapped conditions with & \n",
    "# `[(cond_1) & (cond_2) & ...etc]`.\n",
    "df_only_human_and_kappa_chain = df_keep[\n",
    "    (df_keep[\"HC_species\"] == \"homo_sapiens\") & \n",
    "    (df_keep[\"L_isotype_clean\"].str.contains(\"kappa\", case=False))\n",
    "]\n",
    "\n",
    "# Visualise the data\n",
    "print(f\"Rows, columns: {df_only_human_and_kappa_chain.shape}\")\n",
    "df_only_human_and_kappa_chain.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b77020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>template</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>H_seq</th>\n",
       "      <th>L_seq</th>\n",
       "      <th>H_coordinate_seq</th>\n",
       "      <th>L_coordinate_seq</th>\n",
       "      <th>H_PDB_numbering</th>\n",
       "      <th>L_PDB_numbering</th>\n",
       "      <th>...</th>\n",
       "      <th>resolution</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>HC_species</th>\n",
       "      <th>H_isotype_clean</th>\n",
       "      <th>L_isotype_clean</th>\n",
       "      <th>HC_coordinate_seq</th>\n",
       "      <th>LC_coordinate_seq</th>\n",
       "      <th>HV_seq</th>\n",
       "      <th>LV_seq</th>\n",
       "      <th>disulfide_bond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1n8z</td>\n",
       "      <td>v_template</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>kappa</td>\n",
       "      <td>ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>CYS147(B)-CYS203(B):6.59, CYS134(A)-CYS194(A):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2agj</td>\n",
       "      <td>c_template</td>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>QVTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...</td>\n",
       "      <td>VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKAL...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...</td>\n",
       "      <td>2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,...</td>\n",
       "      <td>1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2-acetamido-2-deoxy-beta-D-glucopyranose-(1-4)...</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>IgM</td>\n",
       "      <td>kappa</td>\n",
       "      <td>SGSASAPTLFPLVSCENSSPSSTVAVGCLAQDFLPDSITFSWKYKN...</td>\n",
       "      <td>RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...</td>\n",
       "      <td>QVTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...</td>\n",
       "      <td>CYS134(H)-CYS215(L):5.61, CYS147(H)-CYS207(H):...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pdb    template Hchain Lchain  \\\n",
       "242  1n8z  v_template      B      A   \n",
       "467  2agj  c_template      H      L   \n",
       "\n",
       "                                                 H_seq  \\\n",
       "242  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "467  QVTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...   \n",
       "\n",
       "                                                 L_seq  \\\n",
       "242  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "467  EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...   \n",
       "\n",
       "                                      H_coordinate_seq  \\\n",
       "242  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "467  VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKAL...   \n",
       "\n",
       "                                      L_coordinate_seq  \\\n",
       "242  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "467  EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...   \n",
       "\n",
       "                                       H_PDB_numbering  \\\n",
       "242  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...   \n",
       "467  2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,...   \n",
       "\n",
       "                                       L_PDB_numbering  ... resolution  \\\n",
       "242  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...  ...       2.52   \n",
       "467  1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,1...  ...       2.60   \n",
       "\n",
       "                                          carbohydrate    HC_species  \\\n",
       "242                                                NaN  homo_sapiens   \n",
       "467  2-acetamido-2-deoxy-beta-D-glucopyranose-(1-4)...  homo_sapiens   \n",
       "\n",
       "     H_isotype_clean L_isotype_clean  \\\n",
       "242             IgG1           kappa   \n",
       "467              IgM           kappa   \n",
       "\n",
       "                                     HC_coordinate_seq  \\\n",
       "242  ASTKGPSVFPLAPSSKSTSGGTAALGCLVKDYFPEPVTVSWNSGAL...   \n",
       "467  SGSASAPTLFPLVSCENSSPSSTVAVGCLAQDFLPDSITFSWKYKN...   \n",
       "\n",
       "                                     LC_coordinate_seq  \\\n",
       "242  RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "467  RTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNA...   \n",
       "\n",
       "                                                HV_seq  \\\n",
       "242  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...   \n",
       "467  QVTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...   \n",
       "\n",
       "                                                LV_seq  \\\n",
       "242  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...   \n",
       "467  EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...   \n",
       "\n",
       "                                        disulfide_bond  \n",
       "242  CYS147(B)-CYS203(B):6.59, CYS134(A)-CYS194(A):...  \n",
       "467  CYS134(H)-CYS215(L):5.61, CYS147(H)-CYS207(H):...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of rows of interest (can be by PDB ID or Heavy Chain Type)\n",
    "\n",
    "# Define the templates of interest\n",
    "# - Variable Heavy & Light template\n",
    "v_template = \"1n8z\"\n",
    "# - Constant Heavy & Light template\n",
    "c_template = \"2agj\"\n",
    "\n",
    "# Filter to template rows. Filters only rows where matching pdb is True. \n",
    "# NOTE: df_filtered is now and independant copy of df_only_human_and_kappa\n",
    "df_filtered = df_only_human_and_kappa_chain[\n",
    "    df_only_human_and_kappa_chain[\"pdb\"].isin([v_template, c_template])\n",
    "].copy()\n",
    "\n",
    "# Add a 'template' annotation column\n",
    "df_filtered.insert(loc=1, column=\"template\", value=None)\n",
    "df_filtered.loc[df_filtered[\"pdb\"] == v_template, \"template\"] = \"v_template\"\n",
    "df_filtered.loc[df_filtered[\"pdb\"] == c_template, \"template\"] = \"c_template\"\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1n8z heavy chain: full sequence matches template cif (220)\n",
      "1n8z light chain: full sequence matches template cif (214)\n",
      "2agj heavy chain: full sequence (226) differs from template cif (225)\n",
      "2agj light chain: full sequence matches template cif (215)\n"
     ]
    }
   ],
   "source": [
    "# DO NOT USE\n",
    "\n",
    "    # Is \"LVTVSS\" present in \"H_coordinate_seq\"? If not True \"H_coordinate_seq has atypical VH-boundary\"\n",
    "    # Is \"LVTVSS\" present in \"HV_coordinate_seq\"? If not true \"Not present in HV_coordinate_seq\n",
    "    # Is \"LVTVSS\" the last 6 characters in \"HV_coordinate_seq\"?\n",
    "    # How many residues appear after \"LVTVSS\"? --> Store these as overlap = str(), along with len(overlap)\n",
    "    # If overlap residues == the first len(overlap) residues of HC_coordinate_seq, then remove them from\n",
    "\n",
    "def template_parse_check(df):\n",
    "    \"\"\"Checks that atom coordinates of the .cif template file exactly match those in the VCAb listing.\"\"\"\n",
    "    \n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        # Define sequence lengths                    \n",
    "        heavy_full_length = len(str(row[\"H_seq\"]))\n",
    "        heavy_cif_length = len(str(row[\"H_coordinate_seq\"]))\n",
    "            \n",
    "        light_full_length = len(str(row[\"L_seq\"]))\n",
    "        light_cif_length = len(str(row[\"L_coordinate_seq\"]))\n",
    "\n",
    "        # Quick Length Check\n",
    "        if heavy_full_length == heavy_cif_length:\n",
    "            print(f\"{row[\"pdb\"]} heavy chain: full sequence matches template cif ({heavy_cif_length})\")\n",
    "        else:\n",
    "            print(f\"{row[\"pdb\"]} heavy chain: full sequence ({heavy_full_length}) differs from template cif ({heavy_cif_length})\")\n",
    "            \n",
    "        if light_full_length == light_cif_length:\n",
    "            print(f\"{row[\"pdb\"]} light chain: full sequence matches template cif ({light_cif_length})\")\n",
    "        else:\n",
    "            print(f\"{row[\"pdb\"]} light chain: full sequence ({light_full_length}) differs from template cif ({light_cif_length})\")\n",
    "            \n",
    "\n",
    "    \n",
    "template_parse_check(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "410ee197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped light chain length: 215\n",
      "Zipped heavy chain length: 225\n",
      "Light chain VC boundary 109th residue\n",
      "Heavy chain VC boundary 120th residue\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([('E', 1),\n",
       "  ('I', 2),\n",
       "  ('V', 3),\n",
       "  ('L', 4),\n",
       "  ('T', 5),\n",
       "  ('Q', 6),\n",
       "  ('S', 7),\n",
       "  ('P', 8),\n",
       "  ('G', 9),\n",
       "  ('T', 10),\n",
       "  ('L', 11),\n",
       "  ('S', 12),\n",
       "  ('L', 13),\n",
       "  ('S', 14),\n",
       "  ('P', 15),\n",
       "  ('G', 16),\n",
       "  ('E', 17),\n",
       "  ('R', 18),\n",
       "  ('A', 19),\n",
       "  ('T', 20),\n",
       "  ('L', 21),\n",
       "  ('S', 22),\n",
       "  ('C', 23),\n",
       "  ('R', 24),\n",
       "  ('A', 25),\n",
       "  ('S', 26),\n",
       "  ('E', 27),\n",
       "  ('T', 28),\n",
       "  ('V', 29),\n",
       "  ('S', 30),\n",
       "  ('N', 31),\n",
       "  ('D', 32),\n",
       "  ('K', 33),\n",
       "  ('V', 34),\n",
       "  ('A', 35),\n",
       "  ('W', 36),\n",
       "  ('Y', 37),\n",
       "  ('Q', 38),\n",
       "  ('Q', 39),\n",
       "  ('K', 40),\n",
       "  ('P', 41),\n",
       "  ('G', 42),\n",
       "  ('Q', 43),\n",
       "  ('A', 44),\n",
       "  ('P', 45),\n",
       "  ('R', 46),\n",
       "  ('L', 47),\n",
       "  ('L', 48),\n",
       "  ('I', 49),\n",
       "  ('Y', 50),\n",
       "  ('G', 51),\n",
       "  ('A', 52),\n",
       "  ('S', 53),\n",
       "  ('S', 54),\n",
       "  ('R', 55),\n",
       "  ('A', 56),\n",
       "  ('T', 57),\n",
       "  ('G', 58),\n",
       "  ('I', 59),\n",
       "  ('P', 60),\n",
       "  ('D', 61),\n",
       "  ('R', 62),\n",
       "  ('F', 63),\n",
       "  ('S', 64),\n",
       "  ('G', 65),\n",
       "  ('S', 66),\n",
       "  ('G', 67),\n",
       "  ('S', 68),\n",
       "  ('G', 69),\n",
       "  ('T', 70),\n",
       "  ('D', 71),\n",
       "  ('F', 72),\n",
       "  ('T', 73),\n",
       "  ('L', 74),\n",
       "  ('S', 75),\n",
       "  ('I', 76),\n",
       "  ('S', 77),\n",
       "  ('G', 78),\n",
       "  ('L', 79),\n",
       "  ('E', 80),\n",
       "  ('P', 81),\n",
       "  ('E', 82),\n",
       "  ('D', 83),\n",
       "  ('F', 84),\n",
       "  ('V', 85),\n",
       "  ('V', 86),\n",
       "  ('Y', 87),\n",
       "  ('Y', 88),\n",
       "  ('C', 89),\n",
       "  ('Q', 90),\n",
       "  ('Q', 91),\n",
       "  ('Y', 92),\n",
       "  ('A', 93),\n",
       "  ('S', 94),\n",
       "  ('S', 95),\n",
       "  ('P', 96),\n",
       "  ('R', 97),\n",
       "  ('T', 98),\n",
       "  ('F', 99),\n",
       "  ('G', 100),\n",
       "  ('Q', 101),\n",
       "  ('G', 102),\n",
       "  ('T', 103),\n",
       "  ('K', 104),\n",
       "  ('V', 105),\n",
       "  ('E', 106),\n",
       "  ('I', 107),\n",
       "  ('K', 108),\n",
       "  ('R', 109),\n",
       "  ('T', 110),\n",
       "  ('V', 111),\n",
       "  ('A', 112),\n",
       "  ('A', 113),\n",
       "  ('P', 114),\n",
       "  ('S', 115),\n",
       "  ('V', 116),\n",
       "  ('F', 117),\n",
       "  ('I', 118),\n",
       "  ('F', 119),\n",
       "  ('P', 120),\n",
       "  ('P', 121),\n",
       "  ('S', 122),\n",
       "  ('D', 123),\n",
       "  ('E', 124),\n",
       "  ('Q', 125),\n",
       "  ('L', 126),\n",
       "  ('K', 127),\n",
       "  ('S', 128),\n",
       "  ('G', 129),\n",
       "  ('T', 130),\n",
       "  ('A', 131),\n",
       "  ('S', 132),\n",
       "  ('V', 133),\n",
       "  ('V', 134),\n",
       "  ('C', 135),\n",
       "  ('L', 136),\n",
       "  ('L', 137),\n",
       "  ('N', 138),\n",
       "  ('N', 139),\n",
       "  ('F', 140),\n",
       "  ('Y', 141),\n",
       "  ('P', 142),\n",
       "  ('R', 143),\n",
       "  ('E', 144),\n",
       "  ('A', 145),\n",
       "  ('K', 146),\n",
       "  ('V', 147),\n",
       "  ('Q', 148),\n",
       "  ('W', 149),\n",
       "  ('K', 150),\n",
       "  ('V', 151),\n",
       "  ('D', 152),\n",
       "  ('N', 153),\n",
       "  ('A', 154),\n",
       "  ('L', 155),\n",
       "  ('Q', 156),\n",
       "  ('S', 157),\n",
       "  ('G', 158),\n",
       "  ('N', 159),\n",
       "  ('S', 160),\n",
       "  ('Q', 161),\n",
       "  ('E', 162),\n",
       "  ('S', 163),\n",
       "  ('V', 164),\n",
       "  ('T', 165),\n",
       "  ('E', 166),\n",
       "  ('Q', 167),\n",
       "  ('D', 168),\n",
       "  ('S', 169),\n",
       "  ('K', 170),\n",
       "  ('D', 171),\n",
       "  ('S', 172),\n",
       "  ('T', 173),\n",
       "  ('Y', 174),\n",
       "  ('S', 175),\n",
       "  ('L', 176),\n",
       "  ('S', 177),\n",
       "  ('S', 178),\n",
       "  ('T', 179),\n",
       "  ('L', 180),\n",
       "  ('T', 181),\n",
       "  ('L', 182),\n",
       "  ('S', 183),\n",
       "  ('K', 184),\n",
       "  ('A', 185),\n",
       "  ('D', 186),\n",
       "  ('Y', 187),\n",
       "  ('E', 188),\n",
       "  ('K', 189),\n",
       "  ('H', 190),\n",
       "  ('K', 191),\n",
       "  ('V', 192),\n",
       "  ('Y', 193),\n",
       "  ('A', 194),\n",
       "  ('C', 195),\n",
       "  ('E', 196),\n",
       "  ('V', 197),\n",
       "  ('T', 198),\n",
       "  ('H', 199),\n",
       "  ('Q', 200),\n",
       "  ('G', 201),\n",
       "  ('L', 202),\n",
       "  ('S', 203),\n",
       "  ('S', 204),\n",
       "  ('P', 205),\n",
       "  ('V', 206),\n",
       "  ('T', 207),\n",
       "  ('K', 208),\n",
       "  ('S', 209),\n",
       "  ('F', 210),\n",
       "  ('N', 211),\n",
       "  ('R', 212),\n",
       "  ('G', 213),\n",
       "  ('E', 214),\n",
       "  ('C', 215)],\n",
       " [('V', 2),\n",
       "  ('T', 3),\n",
       "  ('L', 4),\n",
       "  ('K', 5),\n",
       "  ('E', 6),\n",
       "  ('S', 7),\n",
       "  ('G', 8),\n",
       "  ('P', 9),\n",
       "  ('T', 10),\n",
       "  ('L', 11),\n",
       "  ('V', 12),\n",
       "  ('K', 13),\n",
       "  ('P', 14),\n",
       "  ('T', 15),\n",
       "  ('Q', 16),\n",
       "  ('T', 17),\n",
       "  ('L', 18),\n",
       "  ('T', 19),\n",
       "  ('L', 20),\n",
       "  ('T', 21),\n",
       "  ('C', 22),\n",
       "  ('T', 23),\n",
       "  ('F', 24),\n",
       "  ('S', 25),\n",
       "  ('G', 26),\n",
       "  ('F', 27),\n",
       "  ('S', 28),\n",
       "  ('L', 29),\n",
       "  ('T', 30),\n",
       "  ('T', 31),\n",
       "  ('T', 32),\n",
       "  ('G', 33),\n",
       "  ('E', 34),\n",
       "  ('G', 35),\n",
       "  ('V', 36),\n",
       "  ('G', 37),\n",
       "  ('W', 38),\n",
       "  ('I', 39),\n",
       "  ('R', 40),\n",
       "  ('Q', 41),\n",
       "  ('P', 42),\n",
       "  ('P', 43),\n",
       "  ('G', 44),\n",
       "  ('K', 45),\n",
       "  ('A', 46),\n",
       "  ('L', 47),\n",
       "  ('E', 48),\n",
       "  ('F', 49),\n",
       "  ('L', 50),\n",
       "  ('A', 51),\n",
       "  ('F', 52),\n",
       "  ('I', 53),\n",
       "  ('Y', 54),\n",
       "  ('W', 55),\n",
       "  ('N', 56),\n",
       "  ('D', 57),\n",
       "  ('A', 58),\n",
       "  ('K', 59),\n",
       "  ('R', 60),\n",
       "  ('Y', 61),\n",
       "  ('N', 62),\n",
       "  ('P', 63),\n",
       "  ('S', 64),\n",
       "  ('L', 65),\n",
       "  ('Q', 66),\n",
       "  ('S', 67),\n",
       "  ('R', 68),\n",
       "  ('L', 69),\n",
       "  ('T', 70),\n",
       "  ('I', 71),\n",
       "  ('T', 72),\n",
       "  ('K', 73),\n",
       "  ('D', 74),\n",
       "  ('A', 75),\n",
       "  ('S', 76),\n",
       "  ('K', 77),\n",
       "  ('K', 78),\n",
       "  ('Q', 79),\n",
       "  ('V', 80),\n",
       "  ('V', 81),\n",
       "  ('L', 82),\n",
       "  ('T', 83),\n",
       "  ('L', 84),\n",
       "  ('T', 85),\n",
       "  ('N', 86),\n",
       "  ('L', 87),\n",
       "  ('D', 88),\n",
       "  ('P', 89),\n",
       "  ('V', 90),\n",
       "  ('D', 91),\n",
       "  ('T', 92),\n",
       "  ('A', 93),\n",
       "  ('T', 94),\n",
       "  ('Y', 95),\n",
       "  ('Y', 96),\n",
       "  ('C', 97),\n",
       "  ('A', 98),\n",
       "  ('R', 99),\n",
       "  ('T', 100),\n",
       "  ('S', 101),\n",
       "  ('G', 102),\n",
       "  ('W', 103),\n",
       "  ('D', 104),\n",
       "  ('I', 105),\n",
       "  ('E', 106),\n",
       "  ('F', 107),\n",
       "  ('E', 108),\n",
       "  ('Y', 109),\n",
       "  ('W', 110),\n",
       "  ('G', 111),\n",
       "  ('Q', 112),\n",
       "  ('G', 113),\n",
       "  ('T', 114),\n",
       "  ('L', 115),\n",
       "  ('V', 116),\n",
       "  ('T', 117),\n",
       "  ('V', 118),\n",
       "  ('S', 119),\n",
       "  ('S', 120),\n",
       "  ('G', 121),\n",
       "  ('S', 122),\n",
       "  ('A', 123),\n",
       "  ('S', 124),\n",
       "  ('A', 125),\n",
       "  ('P', 126),\n",
       "  ('T', 127),\n",
       "  ('L', 128),\n",
       "  ('F', 129),\n",
       "  ('P', 130),\n",
       "  ('L', 131),\n",
       "  ('V', 132),\n",
       "  ('S', 133),\n",
       "  ('C', 134),\n",
       "  ('E', 135),\n",
       "  ('N', 136),\n",
       "  ('S', 137),\n",
       "  ('S', 138),\n",
       "  ('P', 139),\n",
       "  ('S', 140),\n",
       "  ('S', 141),\n",
       "  ('T', 142),\n",
       "  ('V', 143),\n",
       "  ('A', 144),\n",
       "  ('V', 145),\n",
       "  ('G', 146),\n",
       "  ('C', 147),\n",
       "  ('L', 148),\n",
       "  ('A', 149),\n",
       "  ('Q', 150),\n",
       "  ('D', 151),\n",
       "  ('F', 152),\n",
       "  ('L', 153),\n",
       "  ('P', 154),\n",
       "  ('D', 155),\n",
       "  ('S', 156),\n",
       "  ('I', 157),\n",
       "  ('T', 158),\n",
       "  ('F', 159),\n",
       "  ('S', 160),\n",
       "  ('W', 161),\n",
       "  ('K', 162),\n",
       "  ('Y', 163),\n",
       "  ('K', 164),\n",
       "  ('N', 165),\n",
       "  ('N', 166),\n",
       "  ('S', 167),\n",
       "  ('D', 168),\n",
       "  ('I', 169),\n",
       "  ('S', 170),\n",
       "  ('S', 171),\n",
       "  ('T', 172),\n",
       "  ('R', 173),\n",
       "  ('G', 174),\n",
       "  ('F', 175),\n",
       "  ('P', 176),\n",
       "  ('S', 177),\n",
       "  ('V', 178),\n",
       "  ('L', 179),\n",
       "  ('R', 180),\n",
       "  ('G', 181),\n",
       "  ('G', 182),\n",
       "  ('K', 183),\n",
       "  ('Y', 184),\n",
       "  ('A', 185),\n",
       "  ('A', 186),\n",
       "  ('T', 187),\n",
       "  ('S', 188),\n",
       "  ('Q', 189),\n",
       "  ('V', 190),\n",
       "  ('L', 191),\n",
       "  ('L', 192),\n",
       "  ('P', 193),\n",
       "  ('S', 194),\n",
       "  ('K', 195),\n",
       "  ('D', 196),\n",
       "  ('V', 197),\n",
       "  ('M', 198),\n",
       "  ('Q', 199),\n",
       "  ('G', 200),\n",
       "  ('T', 201),\n",
       "  ('D', 202),\n",
       "  ('E', 203),\n",
       "  ('H', 204),\n",
       "  ('V', 205),\n",
       "  ('V', 206),\n",
       "  ('C', 207),\n",
       "  ('K', 208),\n",
       "  ('V', 209),\n",
       "  ('Q', 210),\n",
       "  ('H', 211),\n",
       "  ('P', 212),\n",
       "  ('N', 213),\n",
       "  ('G', 214),\n",
       "  ('N', 215),\n",
       "  ('K', 216),\n",
       "  ('E', 217),\n",
       "  ('K', 218),\n",
       "  ('D', 219),\n",
       "  ('V', 220),\n",
       "  ('P', 221),\n",
       "  ('L', 222),\n",
       "  ('P', 223),\n",
       "  ('V', 224),\n",
       "  ('V', 225),\n",
       "  ('I', 226)],\n",
       " 109,\n",
       " 120)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can be called separately for each template\n",
    "def zip_template_cif(df: pd.DataFrame, pdb_code: str):\n",
    "    \"\"\"Takes in a filtered DataFrame and PDB code. Zips residues with PDB coordinates to their respective PDB numbering, \n",
    "    only residues appearing in the x-ray structure are included. Outputs a list of tuples for residues and their numbering.\"\"\"\n",
    "    \n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        if row[\"pdb\"] == pdb_code:\n",
    "            \n",
    "            # Parse .cif Heavy Chain \n",
    "            heavy_cif_residue_list = list(row[\"H_coordinate_seq\"])\n",
    "            heavy_cif_numbering_list = list(map(int, row[\"H_PDB_numbering\"].split(\",\")))\n",
    "            heavy_cif_VC_boundary = int(row[\"pdb_H_VC_Boundary\"])\n",
    "        \n",
    "            # Parse .cif Light Chain\n",
    "            light_cif_residue_list = list(row[\"L_coordinate_seq\"])\n",
    "            light_cif_numbering_list = list(map(int, row[\"L_PDB_numbering\"].split(\",\")))\n",
    "            light_cif_VC_boundary = int(row[\"pdb_L_VC_Boundary\"])\n",
    "\n",
    "            # Create heavy/light chain zips\n",
    "            heavy_zip = (list(zip(heavy_cif_residue_list, heavy_cif_numbering_list)))\n",
    "            light_zip = (list(zip(light_cif_residue_list, light_cif_numbering_list)))\n",
    "            \n",
    "            print(f\"Zipped light chain length: {len(light_zip)}\")\n",
    "            print(f\"Zipped heavy chain length: {len(heavy_zip)}\")\n",
    "            print(f\"Light chain VC boundary {light_cif_VC_boundary}th residue\")\n",
    "            print(f\"Heavy chain VC boundary {heavy_cif_VC_boundary}th residue\")\n",
    "\n",
    "    return (light_zip, heavy_zip, light_cif_VC_boundary, heavy_cif_VC_boundary)\n",
    "\n",
    "zip_template_cif(df_filtered, c_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a0b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped light chain length: 215\n",
      "Zipped heavy chain length: 225\n",
      "Light chain VC boundary 109th residue\n",
      "Heavy chain VC boundary 120th residue\n"
     ]
    }
   ],
   "source": [
    "def get_constant_region(light_zip, heavy_zip, light_boundary, heavy_boundary):\n",
    "    \"\"\"Extracts the tuple after the Variable-Constant boundary within a heavy/light chain zip.\"\"\"\n",
    "\n",
    "    # Expression format: `(return this for (item1, item2) in iterable if condition)`\n",
    "    # expression - what we want to return\n",
    "    # for ... in ... - the loop part\n",
    "    # if ... - optional condition\n",
    "\n",
    "    # Find index of the boundary tuple in each chain\n",
    "    light_boundary_index = next(i for i, (_, num) in enumerate(light_zip) if num == light_boundary)\n",
    "    heavy_boundary_index = next(i for i, (_, num) in enumerate(heavy_zip) if num == heavy_boundary)\n",
    "\n",
    "    #print(f\"Light Boundary tuple index: {light_boundary_index}\")\n",
    "    #print(f\"Heavy Boundary tuple index: {heavy_boundary_index}\")\n",
    "\n",
    "    # Get all tuples after the boundary\n",
    "    light_post_boundary = light_zip[light_boundary_index + 1:]\n",
    "    heavy_post_boundary = heavy_zip[heavy_boundary_index + 1:]  \n",
    "\n",
    "    return (light_post_boundary, heavy_post_boundary)\n",
    "\n",
    "# Use * to unpack the tuple from zip function\n",
    "cl_zip, ch_zip = get_constant_region(*zip_template_cif(df_filtered, c_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb9e3020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped light chain length: 214\n",
      "Zipped heavy chain length: 220\n",
      "Light chain VC boundary 108th residue\n",
      "Heavy chain VC boundary 121th residue\n"
     ]
    }
   ],
   "source": [
    "def get_variable_region(light_zip, heavy_zip, light_boundary, heavy_boundary):\n",
    "    \"\"\"Extracts the tuple before the Variable-Constant boundary within a heavy/light chain zip.\"\"\"\n",
    "\n",
    "    # Find index of the boundary tuple in each chain\n",
    "    light_boundary_index = next(i for i, (_, num) in enumerate(light_zip) if num == light_boundary)\n",
    "    heavy_boundary_index = next(i for i, (_, num) in enumerate(heavy_zip) if num == heavy_boundary)\n",
    "\n",
    "    #print(f\"Light Boundary tuple index: {light_boundary_index}\")\n",
    "    #print(f\"Heavy Boundary tuple index: {heavy_boundary_index}\")\n",
    "\n",
    "    # Get all tuples BEFORE AND INCLUDING the boundary\n",
    "    light_pre_boundary = light_zip[:light_boundary_index + 1]\n",
    "    heavy_pre_boundary = heavy_zip[:heavy_boundary_index + 1]\n",
    "\n",
    "    return (light_pre_boundary, heavy_pre_boundary)\n",
    "\n",
    "# Use * to unpack the tuple from zip function\n",
    "vl_zip, vh_zip = get_variable_region(*zip_template_cif(df_filtered, v_template))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb07979e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recombinant Sequence (light): DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYTTPPTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n",
      "Recombinant Sequence (heavy): EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCSRWGGDGFYAMDYWGQGTLVTVSSAGSASAPTLFPLVSCENSSPSSTVAVGCLAQDFLPDSITFSWKYKNNSDISSTRGFPSVLRGGKYAATSQVLLPSKDVMQGTDEHVVCKVQHPNGNKEKDVPLPVVI\n"
     ]
    }
   ],
   "source": [
    "# The recombinant antibody must only combine V sequence of v_template + C sequence of c_template\n",
    "\n",
    "def make_recombinant_seqs(vl_zip, vh_zip, cl_zip, ch_zip):\n",
    "    \"\"\"Combines the variable and constant regions of 2 different template sequences.\n",
    "    Takes 'zipped' (residue-position sequence) chains, joins VL to CL and VH to CH.\n",
    "    Outputs a tuple of two strings (light_sequence, heavy_sequence).\"\"\"\n",
    "\n",
    "    # Make variable region sequence\n",
    "    vl_str = ''.join(res for res, _ in vl_zip)\n",
    "    vh_str = ''.join(res for res, _ in vh_zip)\n",
    "\n",
    "    # Make constant region sequence\n",
    "    cl_str = ''.join(res for res, _ in cl_zip)\n",
    "    ch_str = ''.join(res for res, _ in ch_zip)\n",
    "\n",
    "    recombinant_seq_light = vl_str + cl_str\n",
    "    recombinant_seq_heavy = vh_str + ch_str\n",
    "\n",
    "    print(f\"Recombinant Sequence (light): {recombinant_seq_light}\")\n",
    "    print(f\"Recombinant Sequence (heavy): {recombinant_seq_heavy}\")\n",
    "\n",
    "    return (recombinant_seq_light, recombinant_seq_heavy)\n",
    "\n",
    "recombinant_seq_light, recombinant_seq_heavy = make_recombinant_seqs(vl_zip, vh_zip, cl_zip, ch_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a7f177d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recombinant Sequence (light): DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYTTPPTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n",
      "Recombinant Sequence (heavy): EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCSRWGGDGFYAMDYWGQGTLVTVSSAGSASAPTLFPLVSCENSSPSSTVAVGCLAQDFLPDSITFSWKYKNNSDISSTRGFPSVLRGGKYAATSQVLLPSKDVMQGTDEHVVCKVQHPNGNKEKDVPLPVVI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>template</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>H_isotype_clean</th>\n",
       "      <th>HC_species</th>\n",
       "      <th>H_coordinate_seq</th>\n",
       "      <th>H_chain_first_residue</th>\n",
       "      <th>H_chain_last_residue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n8z</td>\n",
       "      <td>v_template</td>\n",
       "      <td>B</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2agj</td>\n",
       "      <td>c_template</td>\n",
       "      <td>H</td>\n",
       "      <td>IgM</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKAL...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fab_hybrid</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IgM</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pdb    template Hchain H_isotype_clean    HC_species  \\\n",
       "0        1n8z  v_template      B            IgG1  homo_sapiens   \n",
       "1        2agj  c_template      H             IgM  homo_sapiens   \n",
       "2  Fab_hybrid      target    NaN             IgM  homo_sapiens   \n",
       "\n",
       "                                    H_coordinate_seq  H_chain_first_residue  \\\n",
       "0  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...                    1.0   \n",
       "1  VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKAL...                    2.0   \n",
       "2  EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLE...                    NaN   \n",
       "\n",
       "   H_chain_last_residue  \n",
       "0                 220.0  \n",
       "1                 226.0  \n",
       "2                   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_df_heavies(df_filtered: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates a new dataframe for heavy chain metadata from an already-filtered dataframe.\"\"\"\n",
    "\n",
    "    # Call the recombinant sequence function and assign variables\n",
    "    _, recombinant_seq_heavy = make_recombinant_seqs(vl_zip, vh_zip, cl_zip, ch_zip)\n",
    "\n",
    "    df_heavies = pd.DataFrame({\n",
    "    \"pdb\": df_filtered[\"pdb\"],\n",
    "    \"template\": df_filtered[\"template\"],\n",
    "    \"Hchain\": df_filtered[\"Hchain\"],\n",
    "    \"H_isotype_clean\": df_filtered[\"H_isotype_clean\"],\n",
    "    \"HC_species\": df_filtered[\"HC_species\"],\n",
    "    \"H_coordinate_seq\": df_filtered[\"H_coordinate_seq\"],\n",
    "    })\n",
    "\n",
    "    # Clean Hchain to keep only first character\n",
    "    df_heavies[\"Hchain\"] = df_heavies[\"Hchain\"].str[0]\n",
    "    \n",
    "    first_residue_nos = []\n",
    "    last_residue_nos = []\n",
    "\n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "\n",
    "        # Split the string of numbering to a list and extract start/end values\n",
    "        residue_numbering_list = list(map(int, row[\"H_PDB_numbering\"].split(\",\")))\n",
    "        last_residue_nos.append(residue_numbering_list[-1])\n",
    "        first_residue_nos.append(residue_numbering_list[0])\n",
    "    \n",
    "    #Add new columns to new df\n",
    "    df_heavies[\"H_chain_first_residue\"] = first_residue_nos\n",
    "    df_heavies[\"H_chain_last_residue\"] = last_residue_nos\n",
    "\n",
    "    # Append recombinant hybrid row to the new dataframe\n",
    "    hybrid_row = {\n",
    "        \"pdb\": \"Fab_hybrid\",\n",
    "        \"template\": \"target\",\n",
    "        \n",
    "        # Assigns the constant region's isotype as the isotype for the target\n",
    "        \"H_isotype_clean\": df_filtered.loc[df_filtered[\"template\"] == \"c_template\", \"H_isotype_clean\"].values[0],\n",
    "\n",
    "        # Assigns the species\n",
    "        \"HC_species\": df_filtered.loc[df_filtered[\"template\"] == \"c_template\", \"HC_species\"].values[0],\n",
    "        \n",
    "        # Add the recombinant sequence to the new row dict\n",
    "        \"H_coordinate_seq\": recombinant_seq_heavy\n",
    "    }\n",
    "    \n",
    "    df_heavies = pd.concat([df_heavies, pd.DataFrame([hybrid_row])], ignore_index=True)\n",
    "\n",
    "    return df_heavies\n",
    "\n",
    "df_heavy = make_df_heavies(df_filtered)\n",
    "df_heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7127a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recombinant Sequence (light): DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKLLIYSASFLYSGVPSRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYTTPPTFGQGTKVEIKRTVAAPSVFIFPPSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTLTLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC\n",
      "Recombinant Sequence (heavy): EVQLVESGGGLVQPGGSLRLSCAASGFNIKDTYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQMNSLRAEDTAVYYCSRWGGDGFYAMDYWGQGTLVTVSSAGSASAPTLFPLVSCENSSPSSTVAVGCLAQDFLPDSITFSWKYKNNSDISSTRGFPSVLRGGKYAATSQVLLPSKDVMQGTDEHVVCKVQHPNGNKEKDVPLPVVI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>template</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>H_isotype_clean</th>\n",
       "      <th>HC_species</th>\n",
       "      <th>L_coordinate_seq</th>\n",
       "      <th>L_chain_first_residue</th>\n",
       "      <th>L_chain_last_residue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n8z</td>\n",
       "      <td>v_template</td>\n",
       "      <td>A</td>\n",
       "      <td>IgG1</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2agj</td>\n",
       "      <td>c_template</td>\n",
       "      <td>L</td>\n",
       "      <td>IgM</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fab_hybrid</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IgM</td>\n",
       "      <td>homo_sapiens</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pdb    template Lchain H_isotype_clean    HC_species  \\\n",
       "0        1n8z  v_template      A            IgG1  homo_sapiens   \n",
       "1        2agj  c_template      L             IgM  homo_sapiens   \n",
       "2  Fab_hybrid      target    NaN             IgM  homo_sapiens   \n",
       "\n",
       "                                    L_coordinate_seq  L_chain_first_residue  \\\n",
       "0  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...                    1.0   \n",
       "1  EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...                    1.0   \n",
       "2  DIQMTQSPSSLSASVGDRVTITCRASQDVNTAVAWYQQKPGKAPKL...                    NaN   \n",
       "\n",
       "   L_chain_last_residue  \n",
       "0                 214.0  \n",
       "1                 215.0  \n",
       "2                   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_df_lights(df_filtered: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Creates a new dataframe for light chain metadata from an already-filtered dataframe.\"\"\"\n",
    "\n",
    "    # Call the recombinant sequence function and assign variables\n",
    "    recombinant_seq_light, _ = make_recombinant_seqs(vl_zip, vh_zip, cl_zip, ch_zip)\n",
    "\n",
    "    df_lights = pd.DataFrame({\n",
    "    \"pdb\": df_filtered[\"pdb\"],\n",
    "    \"template\": df_filtered[\"template\"],\n",
    "    \"Lchain\": df_filtered[\"Lchain\"],\n",
    "    \"H_isotype_clean\": df_filtered[\"H_isotype_clean\"],\n",
    "    \"HC_species\": df_filtered[\"HC_species\"],\n",
    "    \"L_coordinate_seq\": df_filtered[\"L_coordinate_seq\"],\n",
    "    })\n",
    "\n",
    "    # Clean Hchain to keep only first character\n",
    "    df_lights[\"Lchain\"] = df_lights[\"Lchain\"].str[0]\n",
    "    \n",
    "    first_residue_nos = []\n",
    "    last_residue_nos = []\n",
    "\n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "\n",
    "        # Split the string of numbering to a list and extract start/end values\n",
    "        residue_numbering_list = list(map(int, row[\"L_PDB_numbering\"].split(\",\")))\n",
    "        last_residue_nos.append(residue_numbering_list[-1])\n",
    "        first_residue_nos.append(residue_numbering_list[0])\n",
    "    \n",
    "    #Add new columns to new df\n",
    "    df_lights[\"L_chain_first_residue\"] = first_residue_nos\n",
    "    df_lights[\"L_chain_last_residue\"] = last_residue_nos\n",
    "\n",
    "    # Append recombinant hybrid row to the new dataframe\n",
    "    hybrid_row = {\n",
    "        \"pdb\": \"Fab_hybrid\",\n",
    "        \"template\": \"target\",\n",
    "        \n",
    "        # Assigns the constant region's isotype as the isotype for the target\n",
    "        \"H_isotype_clean\": df_filtered.loc[df_filtered[\"template\"] == \"c_template\", \"H_isotype_clean\"].values[0],\n",
    "        \n",
    "        # Assigns the species\n",
    "        \"HC_species\": df_filtered.loc[df_filtered[\"template\"] == \"c_template\", \"HC_species\"].values[0],\n",
    "        \n",
    "        # Add the recombinant sequence to the new row dict\n",
    "        \"L_coordinate_seq\": recombinant_seq_light\n",
    "    }\n",
    "    \n",
    "    df_lights = pd.concat([df_lights, pd.DataFrame([hybrid_row])], ignore_index=True)\n",
    "    \n",
    "    return df_lights\n",
    "\n",
    "df_light = make_df_lights(df_filtered)\n",
    "df_light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b58e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fastas(df_l, df_h, fasta_out_dir):\n",
    "    \"\"\"Write 2 fasta files for light and heavy chains.\"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create date-time stamp to add to file name\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create isotype label to add to the filename\n",
    "    isotype = str(df_filtered.query(\"template == 'c_template'\")[\"H_isotype_clean\"].iloc[0])\n",
    "\n",
    "    try:\n",
    "        # ===Light FASTA===\n",
    "        lfilename = f\"light_chain_{isotype}_{timestamp}.fasta\"\n",
    "        stamped_l_file = os.path.join(fasta_out_dir, lfilename)\n",
    "        with open(stamped_l_file, \"w\") as lf:\n",
    "            for _, row in df_l.iterrows():\n",
    "\n",
    "                # Skip fields that are NA\n",
    "                if pd.isna(row[\"Lchain\"]):\n",
    "                    chain = \"\"\n",
    "                else:\n",
    "                    chain = f\"Chain {row[\"Lchain\"]}|\"\n",
    "\n",
    "                header = (\n",
    "                    f'>{row[\"pdb\"]}|{chain}Light_Chain_Fab_{row[\"H_isotype_clean\"]} {row[\"template\"]}|'\n",
    "                    f'{row[\"HC_species\"] if pd.notna(row[\"HC_species\"]) else \"species not listed\"}'\n",
    "                )\n",
    "                sequence = row[\"L_coordinate_seq\"]\n",
    "\n",
    "                lf.write(header + \"\\n\" + sequence + \"\\n\")\n",
    "\n",
    "        # ===Heavy FASTA===\n",
    "        hfilename = f\"heavy_chain_{isotype}_{timestamp}.fasta\"\n",
    "        stamped_h_file = os.path.join(fasta_out_dir, hfilename)\n",
    "        with open(stamped_h_file, \"w\") as hf:\n",
    "            for _, row in df_h.iterrows():\n",
    "\n",
    "                # Skip fields that are NA\n",
    "                if pd.isna(row[\"Hchain\"]):\n",
    "                    chain = \"\"\n",
    "                else:\n",
    "                    chain = f\"Chain {row[\"Hchain\"]}|\"\n",
    "\n",
    "                header = (\n",
    "                    f'>{row[\"pdb\"]}|{chain}Heavy_Chain_Fab_{row[\"H_isotype_clean\"]} {row[\"template\"]}|'\n",
    "                    f'{row[\"HC_species\"] if pd.notna(row[\"HC_species\"]) else \"species not listed\"}'\n",
    "                )\n",
    "                sequence = row[\"H_coordinate_seq\"]\n",
    "\n",
    "                hf.write(header + \"\\n\" + sequence + \"\\n\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error whilst writing FASTA file: {e}\")\n",
    "\n",
    "import my_run_info\n",
    "write_fastas(df_light, df_heavy, my_run_info.fasta_out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a3df456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>template</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>L_chain_first_residue</th>\n",
       "      <th>H_chain_first_residue</th>\n",
       "      <th>L_chain_last_residue</th>\n",
       "      <th>H_chain_last_residue</th>\n",
       "      <th>light_chain_is_first</th>\n",
       "      <th>start_point</th>\n",
       "      <th>start_letter</th>\n",
       "      <th>gapped_seq_1</th>\n",
       "      <th>end_point</th>\n",
       "      <th>end_letter</th>\n",
       "      <th>gapped_seq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n8z</td>\n",
       "      <td>v_template</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2agj</td>\n",
       "      <td>c_template</td>\n",
       "      <td>L</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fab_hybrid</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pdb    template Lchain Hchain  L_chain_first_residue  \\\n",
       "0        1n8z  v_template      A      B                    1.0   \n",
       "1        2agj  c_template      L      H                    1.0   \n",
       "2  Fab_hybrid      target    NaN    NaN                    NaN   \n",
       "\n",
       "   H_chain_first_residue  L_chain_last_residue  H_chain_last_residue  \\\n",
       "0                    1.0                 214.0                 220.0   \n",
       "1                    2.0                 215.0                 226.0   \n",
       "2                    NaN                   NaN                   NaN   \n",
       "\n",
       "  light_chain_is_first start_point start_letter gapped_seq_1 end_point  \\\n",
       "0                 None        None         None         None      None   \n",
       "1                 None        None         None         None      None   \n",
       "2                 None        None         None         None      None   \n",
       "\n",
       "  end_letter gapped_seq_2  \n",
       "0       None         None  \n",
       "1       None         None  \n",
       "2       None         None  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine heavy and light chain dataframes into one for .pir creation.\n",
    "merged_df = pd.merge(df_light, df_heavy, on=[\"pdb\", \"template\", \"H_isotype_clean\", \"HC_species\"])\n",
    "merged_df\n",
    "\n",
    "# Filter redundant columns\n",
    "df_combined = merged_df[[\n",
    "    \"pdb\", \"template\", \"Lchain\", \"Hchain\", \"L_chain_first_residue\", \n",
    "    \"H_chain_first_residue\", \"L_chain_last_residue\", \"H_chain_last_residue\"\n",
    "]].copy()\n",
    "\n",
    "# Add empty columns\n",
    "df_combined[\"light_chain_is_first\"] = None\n",
    "df_combined[\"start_point\"] = None\n",
    "df_combined[\"start_letter\"] = None\n",
    "df_combined[\"gapped_seq_1\"] = None\n",
    "df_combined[\"end_point\"] = None\n",
    "df_combined[\"end_letter\"] = None\n",
    "df_combined[\"gapped_seq_2\"] = None\n",
    "\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "384d190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IgM\n"
     ]
    }
   ],
   "source": [
    "# access the Ig label of the c_template row[\"pdb\"] and add it to\n",
    "# the file path\n",
    "# NOTE: add this to the write FASTA function\n",
    "for idx, row in df_filtered.iterrows():\n",
    "    if row[\"pdb\"] == c_template:\n",
    "        isotype_label = str(row[\"H_isotype_clean\"])\n",
    "        \n",
    "print(isotype_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dont run this cell. THIS DOES NOT WORK because SeqRecords class object can only hold .id, .desc and .seq.\n",
    "from Bio import SeqIO\n",
    "\n",
    "records = SeqIO.parse(\"THIS_IS_YOUR_INPUT_FILE.clustal\", \"clustal\")\n",
    "count = SeqIO.write(records, \"THIS_IS_YOUR_OUTPUT_FILE.pir\", \"pir\")\n",
    "print(\"Converted %i records\" % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a27dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C']\n",
      "['L', 'H', 'A']\n"
     ]
    }
   ],
   "source": [
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "import os\n",
    "\n",
    "def cif_parse(pdb: str, cif_fname: str, filepath: str):\n",
    "    \"\"\"Parses .cif and determines correct chain order for MODELLER.\"\"\"\n",
    "    from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "    import os\n",
    "\n",
    "    # Set full path\n",
    "    full_cif_path = os.path.join(filepath, cif_fname)\n",
    "\n",
    "    # Initialise parser\n",
    "    parser = MMCIFParser(QUIET=True)\n",
    "\n",
    "    # Load structure\n",
    "    structure = parser.get_structure(pdb, full_cif_path)\n",
    "\n",
    "    # Extract first model (usually there's only one)\n",
    "    model = next(structure.get_models())\n",
    "\n",
    "    # Get chains in order\n",
    "    cif_chain_order = [chain.id for chain in model]\n",
    "\n",
    "    print(cif_chain_order)\n",
    "\n",
    "    return cif_chain_order\n",
    "\n",
    "import my_run_info\n",
    "v_cif_chain_order = cif_parse(v_template, f\"{v_template}.cif\", my_run_info.cif_dir)\n",
    "c_cif_chain_order = cif_parse(c_template, f\"{c_template}.cif\", my_run_info.cif_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec546f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 'A', 220, 'B')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redundant\n",
    "def relevant_chains(pdb, df, cif_chain_order):\n",
    "    \"\"\"Extracts relevant chains from dataframes\"\"\"\n",
    "\n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"pdb\"] == pdb:\n",
    "            l_chain_letter = row[\"Lchain\"]\n",
    "            h_chain_letter = row[\"Hchain\"]\n",
    "\n",
    "            relevant_chains = [chain_id for chain_id in cif_chain_order if chain_id in (h_chain_letter, l_chain_letter)]\n",
    "            print(relevant_chains)\n",
    "\n",
    "            if relevant_chains[0] == l_chain_letter:\n",
    "                start_chain = l_chain_letter\n",
    "                start_point = int(row[\"L_chain_first_residue\"])\n",
    "                end_chain = h_chain_letter\n",
    "                end_point = int(row[\"H_chain_last_residue\"])\n",
    "\n",
    "            if relevant_chains[0] == h_chain_letter:\n",
    "                start_chain = h_chain_letter\n",
    "                start_point = int(row[\"H_chain_last_residue\"])\n",
    "                end_chain = l_chain_letter\n",
    "                end_point = int(row[\"L_chain_first_residue\"])\n",
    "\n",
    "    return (start_point, start_chain, end_point, end_chain)\n",
    "\n",
    "\n",
    "relevant_chains(v_template, df_combined, v_cif_chain_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3508d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B']\n",
      "['L', 'H']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb</th>\n",
       "      <th>template</th>\n",
       "      <th>Lchain</th>\n",
       "      <th>Hchain</th>\n",
       "      <th>L_chain_first_residue</th>\n",
       "      <th>H_chain_first_residue</th>\n",
       "      <th>L_chain_last_residue</th>\n",
       "      <th>H_chain_last_residue</th>\n",
       "      <th>light_chain_is_first</th>\n",
       "      <th>start_point</th>\n",
       "      <th>start_letter</th>\n",
       "      <th>gapped_seq_1</th>\n",
       "      <th>end_point</th>\n",
       "      <th>end_letter</th>\n",
       "      <th>gapped_seq_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1n8z</td>\n",
       "      <td>v_template</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDV-NTAVAWYQQKPGKAPK...</td>\n",
       "      <td>220</td>\n",
       "      <td>B</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKD--TYIHWVRQAPGKG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2agj</td>\n",
       "      <td>c_template</td>\n",
       "      <td>L</td>\n",
       "      <td>H</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...</td>\n",
       "      <td>226</td>\n",
       "      <td>H</td>\n",
       "      <td>-VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fab_hybrid</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DIQMTQSPSSLSASVGDRVTITCRASQDV-NTAVAWYQQKPGKAPK...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFNIKD--TYIHWVRQAPGKG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pdb    template Lchain Hchain  L_chain_first_residue  \\\n",
       "0        1n8z  v_template      A      B                    1.0   \n",
       "1        2agj  c_template      L      H                    1.0   \n",
       "2  Fab_hybrid      target    NaN    NaN                    NaN   \n",
       "\n",
       "   H_chain_first_residue  L_chain_last_residue  H_chain_last_residue  \\\n",
       "0                    1.0                 214.0                 220.0   \n",
       "1                    2.0                 215.0                 226.0   \n",
       "2                    NaN                   NaN                   NaN   \n",
       "\n",
       "  light_chain_is_first start_point start_letter  \\\n",
       "0                 True           1            A   \n",
       "1                 True           1            L   \n",
       "2                 None        None         None   \n",
       "\n",
       "                                        gapped_seq_1 end_point end_letter  \\\n",
       "0  DIQMTQSPSSLSASVGDRVTITCRASQDV-NTAVAWYQQKPGKAPK...       220          B   \n",
       "1  EIVLTQSPGTLSLSPGERATLSCRASETVSNDKVAWYQQKPGQAPR...       226          H   \n",
       "2  DIQMTQSPSSLSASVGDRVTITCRASQDV-NTAVAWYQQKPGKAPK...      None       None   \n",
       "\n",
       "                                        gapped_seq_2  \n",
       "0  EVQLVESGGGLVQPGGSLRLSCAASGFNIKD--TYIHWVRQAPGKG...  \n",
       "1  -VTLKESGPTLVKPTQTLTLTCTFSGFSLTTTGEGVGWIRQPPGKA...  \n",
       "2  EVQLVESGGGLVQPGGSLRLSCAASGFNIKD--TYIHWVRQAPGKG...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relevant_chains(df, v_cif_chain_order, c_cif_chain_order):\n",
    "    \"\"\"Extracts relevant chains from dataframes\"\"\"\n",
    "\n",
    "    # Using iterrows for stable behaviour in pandas\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"pdb\"] == v_template:\n",
    "            l_chain_letter = row[\"Lchain\"]\n",
    "            h_chain_letter = row[\"Hchain\"]\n",
    "\n",
    "            v_relevant_chains = [chain_id for chain_id in v_cif_chain_order if chain_id in (h_chain_letter, l_chain_letter)]\n",
    "            print(v_relevant_chains)\n",
    "\n",
    "            if v_relevant_chains[0] == l_chain_letter:\n",
    "                # assign True/False to light_chain_is_first column\n",
    "                df.at[idx, \"light_chain_is_first\"] = True\n",
    "                df.at[idx, \"start_point\"] = int(row[\"L_chain_first_residue\"])\n",
    "                df.at[idx, \"start_letter\"] = row[\"Lchain\"]\n",
    "                df.at[idx, \"end_point\"] = int(row[\"H_chain_last_residue\"])\n",
    "                df.at[idx, \"end_letter\"] = row[\"Hchain\"]\n",
    "            else:\n",
    "                df.at[idx, \"light_chain_is_first\"] = False\n",
    "                df.at[idx, \"start_point\"] = int(row[\"H_chain_first_residue\"])\n",
    "                df.at[idx, \"start_letter\"] = row[\"Hchain\"]\n",
    "                df.at[idx, \"end_point\"] = int(row[\"L_chain_last_residue\"])\n",
    "                df.at[idx, \"end_letter\"] = row[\"Lchain\"]\n",
    "\n",
    "        if row[\"pdb\"] == c_template:\n",
    "            l_chain_letter = row[\"Lchain\"]\n",
    "            h_chain_letter = row[\"Hchain\"]\n",
    "\n",
    "            c_relevant_chains = [chain_id for chain_id in c_cif_chain_order if chain_id in (h_chain_letter, l_chain_letter)]\n",
    "            print(c_relevant_chains)\n",
    "\n",
    "            if c_relevant_chains[0] == l_chain_letter:\n",
    "                df.at[idx, \"light_chain_is_first\"] = True\n",
    "                df.at[idx, \"start_point\"] = int(row[\"L_chain_first_residue\"])\n",
    "                df.at[idx, \"start_letter\"] = row[\"Lchain\"]\n",
    "                df.at[idx, \"end_point\"] = int(row[\"H_chain_last_residue\"])\n",
    "                df.at[idx, \"end_letter\"] = row[\"Hchain\"]\n",
    "            else:\n",
    "                df.at[idx, \"light_chain_is_first\"] = False\n",
    "                df.at[idx, \"start_point\"] = int(row[\"H_chain_first_residue\"])\n",
    "                df.at[idx, \"start_letter\"] = row[\"Hchain\"]\n",
    "                df.at[idx, \"end_point\"] = int(row[\"L_chain_last_residue\"])\n",
    "                df.at[idx, \"end_letter\"] = row[\"Lchain\"]\n",
    "    return df\n",
    "\n",
    "relevant_chains(df_combined, v_cif_chain_order, c_cif_chain_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a5304c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_run_info\n",
    "\n",
    "def extract_gapped_seqs(df, msa_filepath, light_clustal_fname, heavy_clustal_fname):\n",
    "    \"\"\"Parses .aln-clustal files with Bio.SeqIO and extracts the gapped sequences.\"\"\"\n",
    "\n",
    "    from Bio import SeqIO\n",
    "    from Bio import AlignIO\n",
    "    import os\n",
    "\n",
    "    # Read clustal files\n",
    "    def load_gapped_seqs(filename):\n",
    "        full_clustal_path = os.path.join(msa_filepath, filename)\n",
    "        alignment = AlignIO.read(full_clustal_path, \"clustal\")\n",
    "\n",
    "        # Dictionary of alignments using a for loop to return {ID: seq...}\n",
    "        return {record.id.split(\"|\")[0].lower(): str(record.seq) for record in alignment}\n",
    "\n",
    "    # Load both alignments\n",
    "    light_seqs = load_gapped_seqs(light_clustal_fname)\n",
    "    heavy_seqs = load_gapped_seqs(heavy_clustal_fname)\n",
    "    \n",
    "    # Assign sequences to gapped_seq_1 and gapped_seq_2 if \n",
    "    # light_chain_is_first is True, otherwise 2 then 1\n",
    "    for idx, row in df.iterrows():\n",
    "        pdb = row[\"pdb\"].lower()\n",
    "        if row[\"light_chain_is_first\"] is True:\n",
    "            df.at[idx, \"gapped_seq_1\"] = light_seqs.get(pdb, \"\").replace(\"\\n\", \"\")\n",
    "            df.at[idx, \"gapped_seq_2\"] = heavy_seqs.get(pdb, \"\").replace(\"\\n\", \"\")\n",
    "        elif row[\"light_chain_is_first\"] is False:\n",
    "            df.at[idx, \"gapped_seq_1\"] = heavy_seqs.get(pdb, \"\").replace(\"\\n\", \"\")\n",
    "            df.at[idx, \"gapped_seq_2\"] = light_seqs.get(pdb, \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "    # Handle Fab_hybrid row manually by finding the target row\n",
    "    hybrid_idx = df[df[\"pdb\"].str.lower() == \"fab_hybrid\"].index\n",
    "    if not hybrid_idx.empty:\n",
    "        idx = hybrid_idx[0]\n",
    "        df.at[idx, \"gapped_seq_1\"] = light_seqs.get(\"fab_hybrid\", \"\").replace(\"\\n\", \"\")\n",
    "        df.at[idx, \"gapped_seq_2\"] = heavy_seqs.get(\"fab_hybrid\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "df_for_pir = extract_gapped_seqs(\n",
    "    df_combined,\n",
    "    my_run_info.clustal_out_dir,\n",
    "    light_clustal_fname=\"Fab_alignment_IgM_light.aln-clustal\", # replace this with automation\n",
    "    heavy_clustal_fname=\"Fab_alignment_IgM_heavy.aln-clustal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45198302",
   "metadata": {},
   "source": [
    ">P1;1n8z\n",
    "structureX:1n8z:1:A:220:B:V_Var_Template:::\n",
    "DIQMTQSPSSLSASVGDRVTITCRASQDV-NTAVAWYQQKPGKAPKLLIYSASFLYSGVP\n",
    "SRFSGSRSGTDFTLTISSLQPEDFATYYCQQHYTTPPTFGQGTKVEIKRTVAAPSVFIFP\n",
    "PSDEQLKSGTASVVCLLNNFYPREAKVQWKVDNALQSGNSQESVTEQDSKDSTYSLSSTL\n",
    "TLSKADYEKHKVYACEVTHQGLSSPVTKSFNRGEC/EVQLVESGGGLVQPGGSLRLSCAA\n",
    "SGFNIKD--TYIHWVRQAPGKGLEWVARIYPTNGYTRYADSVKGRFTISADTSKNTAYLQ\n",
    "MNSLRAEDTAVYYCSRWGGDGFYAMDYWGQGTLVTVSSASTKGPSVFPLAPSSKSTSGGT\n",
    "AALGCLVKDYFPEPVTVSWNSGAL--TSGVHTFPAVLQSSGLYSLSSVVTVPSSSLG---\n",
    "TQTYICNVNHKPSNTKVDKKVEP--*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c25d9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The allowed format:\n",
    "# >P1;3m8o\n",
    "# structure:pdb_file:.:.:.:.::::\n",
    "# seq1---/seq2---*\n",
    "\n",
    "def write_modeller_pir(df: pd.DataFrame, out_path: str):\n",
    "    \"\"\"Writes a .pir file from a df containing gapped sequences\"\"\"\n",
    "    \n",
    "    with open(out_path, \"w\") as pir:\n",
    "        for _, row in df.iterrows():\n",
    "            if row[\"pdb\"] == v_template:\n",
    "                \n",
    "                v_pir_header = (\n",
    "                    f\">P1;{row['pdb']}\\n\"\n",
    "                    f\"structureX:{row['pdb']}:{row[\"start_point\"]}:{row[\"start_letter\"]}:{row[\"end_point\"]}:{row[\"end_letter\"]}:\"\n",
    "                    f\":variable_template:::\\n\"\n",
    "                )\n",
    "                v_gapped_sequence = (f\"{row['gapped_seq_1']}/{row['gapped_seq_2']}*\\n\")\n",
    "\n",
    "            if row[\"pdb\"] == c_template:\n",
    "\n",
    "                c_pir_header = (\n",
    "                    f\">P1;{row['pdb']}\\n\"\n",
    "                    f\"structureX:{row['pdb']}:{row[\"start_point\"]}:{row[\"start_letter\"]}:{row[\"end_point\"]}:{row[\"end_letter\"]}:\"\n",
    "                    f\":constant_template_{isotype_label}:::\\n\"\n",
    "                )\n",
    "                c_gapped_sequence = (f\"{row['gapped_seq_1']}/{row['gapped_seq_2']}*\")\n",
    "\n",
    "            if row[\"template\"] == \"target\":\n",
    "\n",
    "                target_pir_header = (\n",
    "                    f\">P1;{row['pdb']}_{isotype_label}_target\\n\"\n",
    "                    f\"sequence:{row['pdb']}_{isotype_label}_target::.::.:hybrid_{isotype_label}_target:::\"\n",
    "                )\n",
    "                target_gapped_sequence = (f\"{row['gapped_seq_1']}/{row['gapped_seq_2']}*\")\n",
    "\n",
    "        pir.write(v_pir_header + v_gapped_sequence)\n",
    "        pir.write(c_pir_header + c_gapped_sequence)\n",
    "        pir.write(target_pir_header + target_gapped_sequence)\n",
    "\n",
    "write_modeller_pir(df_for_pir, \"../pir_files/new_alignment_IgM.pir\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
